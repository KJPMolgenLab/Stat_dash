{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Organoid Morphological Analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This sets the matplotlib backend to be interactive\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages and helper functions from code folder\n",
    "from helper_functions import *\n",
    "import datetime as dt\n",
    "import importlib\n",
    "import sys\n",
    "import psutil\n",
    "from dask.distributed import Client\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import umap\n",
    "import pandas as pd\n",
    "from sklearn.manifold import TSNE\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## If you wanna use dask distributed, execute the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_dask_parameters(percentage=100):\n",
    "    # Ensure the percentage is between 1 and 100\n",
    "    percentage = max(1, min(percentage, 100))\n",
    "    \n",
    "    # Calculate the fraction of resources to use\n",
    "    fraction = percentage / 100.0\n",
    "    \n",
    "    # Get the number of physical cores and logical processors\n",
    "    physical_cores = psutil.cpu_count(logical=False)\n",
    "    logical_processors = psutil.cpu_count(logical=True)\n",
    "    \n",
    "    # Get the total memory in bytes and convert it to GB\n",
    "    total_memory_gb = psutil.virtual_memory().total / (1024 ** 3)\n",
    "    \n",
    "    # Calculate the number of workers and threads per worker to use\n",
    "    n_workers = max(1, int(physical_cores * fraction))\n",
    "    n_threads_per_worker = max(1, int((logical_processors * fraction) // n_workers))\n",
    "    \n",
    "    # Calculate the memory limit per worker\n",
    "    memory_per_worker = (total_memory_gb * fraction) / n_workers\n",
    "    \n",
    "    return {\n",
    "        \"n_workers\": n_workers,\n",
    "        \"threads_per_worker\": n_threads_per_worker,\n",
    "        \"memory_limit\": f\"{memory_per_worker:.2f}GB\"\n",
    "    }\n",
    "\n",
    "def create_dask_client(percentage=100):\n",
    "    params = calculate_dask_parameters(percentage)\n",
    "    client = Client(n_workers=params[\"n_workers\"],\n",
    "                    threads_per_worker=params[\"threads_per_worker\"],\n",
    "                    memory_limit=params[\"memory_limit\"])\n",
    "    return client\n",
    "\n",
    "# Usage\n",
    "percentage_to_use = 90  # Example: use 75% of the computer's resources\n",
    "client = create_dask_client(percentage_to_use)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Declaration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the image folder path and output json path\n",
    "folder_path = \"/files/data\"\n",
    "output_folder = \"/files/data/results\"\n",
    "output_prefix = \"B22_D34_H9_QPRT_KO\"\n",
    "target = \"condition\"\n",
    "\n",
    "# Create the output folder if it does not exist\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "outputname = dt.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")+\"_\"+output_prefix\n",
    "output_json_path = output_folder+\"/\"+outputname+\"metadata.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reads Metadata from Filenames \n",
    "To do metadata read from input file provided by user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specifiy the extra metadata and condition rules\n",
    "extra_metadata = {\n",
    "}\n",
    "\n",
    "# Conditional rules included in the metadata\n",
    "condition_rules = {\n",
    "    'day': {\n",
    "        'd17' : \"Day 17\",\n",
    "        'd24' : \"Day 24\",\n",
    "        'd34' : \"Day 34\",\n",
    "        'd36' : \"Day 36\",\n",
    "        'd45' : \"Day 45\",\n",
    "        'd47' : \"Day 47\",\n",
    "        'd49' : \"Day 49\",\n",
    "    },\n",
    "    'condition' : {\n",
    "        'WT' : \"WT\",\n",
    "        'NTC' : \"NTC\",\n",
    "        'Q2.1' : \"Q2.1\",\n",
    "        'Q2.2' : \"Q2.2\",\n",
    "    },\n",
    "    'molar' : {\n",
    "        '0mM' : \"0mM PA\",\n",
    "        '5mM' : \"5mM PA\",\n",
    "        'HIL6' : \"HIL6\",\n",
    "        'default' : \"No PA\"\n",
    "    }, \n",
    "    'excluded' : {\n",
    "        'Trash' : True,\n",
    "        'TRASH' : True\n",
    "    }\n",
    "}\n",
    "\n",
    "image_metadata = get_image_metadata(folder_path, extra_metadata, condition_rules)\n",
    "save_metadata_as_xlsx(image_metadata, output_folder+\"/\"+outputname+\"_image_metadata.xlsx\")\n",
    "\n",
    "image_files = list(image_metadata.keys())\n",
    "\n",
    "# Filter image_metadata where 'molar' is '0mM PA'\n",
    "filtered_metadata = {k: v for k, v in image_metadata.items() if v['excluded'] != True}\n",
    "filtered_image_files = list(filtered_metadata.keys())\n",
    "\n",
    "\n",
    "print(f\"Number of images: {len(image_files)}\")\n",
    "print(f\"Number of images after filtering: {len(filtered_image_files)}\")\n",
    "display(pd.DataFrame(filtered_metadata).T)\n",
    "\n",
    "image_metadata = filtered_metadata\n",
    "image_files = filtered_image_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run analysis and update metadata with the values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for 75 images the analysis takes about 1m 44 sec (i.e. ~1.5sec per image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata, statistics, segmented_organoids, hu_moments, flags, curvatures, inflection_points, smooth_contours = update_metadata_with_analysis(folder_path, image_metadata, image_files)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plots the flagged images into a pdf file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a PDF file to save the plots\n",
    "\n",
    "if(flags):\n",
    "    pdf_path = output_folder+\"/\"+outputname+\"_flagged_images.pdf\"\n",
    "    with PdfPages(pdf_path) as pdf:\n",
    "        # Iterate through the flagged images\n",
    "        for i, image_file in enumerate(image_files):\n",
    "            if flags[i]:  # Check if there are any flags for the current image\n",
    "                image = segmented_organoids[i]  # Get the corresponding organoid image\n",
    "                flag_text = ', '.join(flags[i])  # Join the flags into a single string\n",
    "\n",
    "                # Plot the image\n",
    "                plt.figure()\n",
    "                plt.imshow(image, cmap='gray')\n",
    "                plt.title(image_file)\n",
    "                plt.xlabel(flag_text)\n",
    "                pdf.savefig() # Save the current figure to the PDF\n",
    "                plt.close()  # Close the figure to free up memory\n",
    "\n",
    "    print(f\"PDF saved to {pdf_path}\")\n",
    "else:\n",
    "    print(\"No flagged images found\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute this cell if you want to remove all the flagged organoids from the metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = remove_flagged_from_metadata(metadata, flags)\n",
    "\n",
    "print(len(segmented_organoids))\n",
    "# Create an index of images not in metadata.keys\n",
    "index_images = [True if image in metadata.keys() else False for image in image_files] \n",
    "statistics = [data for data, include in zip(statistics, index_images) if include]   \n",
    "segmented_organoids =  [data for data, include in zip(segmented_organoids, index_images) if include]\n",
    "hu_moments= [data for data, include in zip(hu_moments, index_images) if include]\n",
    "curvatures = [data for data, include in zip(curvatures, index_images) if include]\n",
    "inflection_points = [data for data, include in zip(inflection_points, index_images) if include]\n",
    "smooth_contours = [data for data, include in zip(smooth_contours, index_images) if include]\n",
    "print(len(segmented_organoids))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute this cell to save the metadata to an Excel sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_metadata_as_xlsx(metadata, output_folder+\"/\"+outputname+\"_analysis_metadata.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute this cell to read the metadata from the provided Excel sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save_metadata_as_xlsx(metadata, \"analysis_metadata.xlsx\")\n",
    "# metadata = read_metadata_from_xlsx(\"analysis_metadata.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converts metadata to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert metadata to DataFrame\n",
    "df = pd.DataFrame.from_dict(metadata, orient='index').drop(columns=['background_uniformity'])\n",
    "\n",
    "# Convert the 'hu_moments' column from string to list of numbers\n",
    "#df['hu_moments'] = df['hu_moments'].apply(ast.literal_eval)\n",
    "\n",
    "# Expand hu_moments into separate columns\n",
    "hu_moments_df = pd.DataFrame(df['hu_moments'].tolist(), index=df.index)\n",
    "hu_moments_df.columns = [f'hu_moment_{i}' for i in range(1, hu_moments_df.shape[1] + 1)]\n",
    "\n",
    "# Concatenate the original dataframe with the new hu_moments columns\n",
    "df = pd.concat([df, hu_moments_df], axis=1)\n",
    "\n",
    "# Drop the original hu_moments column if it's no longer needed\n",
    "df.drop(columns=['hu_moments'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create a pdf with umap plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import StandardScaler\n",
    "# Select features for UMAP\n",
    "feature_columns = ['circularity', 'roundness', 'area', 'perimeter', 'feret max', 'feret min', 'contrast', 'dissimilarity', 'homogeneity', 'energy', 'correlation', 'aspect_ratio', 'dne', 'inflection_points', 'background_transparency'] + hu_moments_df.columns.tolist()\n",
    "\n",
    "\n",
    "X = df[feature_columns].values\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Perform UMAP dimensionality reduction\n",
    "umap_model = umap.UMAP(n_neighbors=15, min_dist=0.1, n_components=2, random_state=42)\n",
    "umap_embedding = umap_model.fit_transform(X_scaled)\n",
    "\n",
    "# Add UMAP results to DataFrame\n",
    "df['umap_x'] = umap_embedding[:, 0]\n",
    "df['umap_y'] = umap_embedding[:, 1]\n",
    "\n",
    "# Perform T-SNE dimensionality reduction\n",
    "tsne_model = TSNE(n_components=2, random_state=42)\n",
    "tsne_embedding = tsne_model.fit_transform(X_scaled)\n",
    "\n",
    "# Add T-SNE results to DataFrame\n",
    "df['tsne_x'] = tsne_embedding[:, 0]\n",
    "df['tsne_y'] = tsne_embedding[:, 1]\n",
    "\n",
    "pdf_path = output_folder+\"/\"+outputname+\"_UMAP.pdf\"\n",
    "with PdfPages(pdf_path) as pdf:\n",
    "    scatter = plt.scatter(df['umap_x'], df['umap_y'], \n",
    "                          c=df[target].astype('category').cat.codes, \n",
    "                          cmap='viridis', s=5)\n",
    "    # Fix legend\n",
    "    handles, _ = scatter.legend_elements()\n",
    "    plt.legend(handles, df[target].astype('category').cat.categories, \n",
    "               title=target, \n",
    "               loc='upper center', ncol = len(np.unique_values(df[target])),\n",
    "               bbox_to_anchor=(0.5, 1.15))\n",
    "    pdf.savefig()\n",
    "    plt.close()\n",
    "    print(f\"PDF saved to {pdf_path}\")\n",
    "\n",
    "# Save the DataFrame with UMAP and T-SNE results\n",
    "save_df_as_xlsx(df, output_folder+\"/\"+outputname+  \"_analysis_metadata_all_cleaned.xlsx\")\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run /files/dashapp_current.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Visualize the clusters with images as markers\n",
    "\n",
    "plot_with_images(df, target, segmented_organoids, output_folder, outputname)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the Analysis with the contour coloured in the DNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(5)):\n",
    "    plot_analysis(segmented_organoids[i], statistics[i], flags[i], output_folder=output_folder,output_name=f'analysis_{image_files[i].split(\".\")[0]}')\n",
    "    plot_contour_with_dne(segmented_organoids[i], smooth_contours[i], curvatures[i], inflection_points[i], output_folder=output_folder,output_name=f'analysis_{image_files[i].split(\".\")[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision trees and Random Forest Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports for Decision Trees and RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mplcursors\n",
    "from skimage import data, segmentation, feature, future\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(os.path.join(folder_path, image_files[27]))\n",
    "\n",
    "\n",
    "#image = segmented_organoids[0]\n",
    "image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Load an example image\n",
    "img = image\n",
    "\n",
    "# Initialize training labels\n",
    "training_labels = np.zeros(img.shape[:2], dtype=np.uint8)\n",
    "\n",
    "# Display the image\n",
    "fig, ax = plt.subplots()\n",
    "ax.imshow(img)\n",
    "plt.title(\"Click to label regions. Press '1'-'5' to change label.\")\n",
    "cursor = mplcursors.cursor(hover=True)\n",
    "\n",
    "# Keep track of current label\n",
    "current_label = [1]  # Use a list to allow modification within the event handler\n",
    "\n",
    "def update_label(event):\n",
    "    if event.key in '12345':\n",
    "        current_label[0] = int(event.key)\n",
    "        print(f\"Current label: {current_label[0]}\")\n",
    "\n",
    "def on_click(event):\n",
    "    if event.inaxes:\n",
    "        x, y = int(event.xdata), int(event.ydata)\n",
    "        radius = 10  # Adjust the radius as needed\n",
    "        training_labels[max(y-radius, 0):min(y+radius, img.shape[0]), max(x-radius, 0):min(x+radius, img.shape[1])] = current_label[0]\n",
    "        ax.add_patch(plt.Circle((x, y), radius, color='red', fill=False))\n",
    "        fig.canvas.draw()\n",
    "\n",
    "fig.canvas.mpl_connect('button_press_event', on_click)\n",
    "fig.canvas.mpl_connect('key_press_event', update_label)\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After labeling, proceed with segmentation\n",
    "sigma_min = 1\n",
    "sigma_max = 32\n",
    "features_func = partial(\n",
    "    feature.multiscale_basic_features,\n",
    "    intensity=True,\n",
    "    edges=True,\n",
    "    texture=True,\n",
    "    sigma_min=sigma_min,\n",
    "    sigma_max=sigma_max,\n",
    "    channel_axis=-1\n",
    ")\n",
    "features = features_func(img)\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=50, n_jobs=-1, max_depth=10, max_samples=0.05)\n",
    "clf = future.fit_segmenter(training_labels, features, clf)\n",
    "result = future.predict_segmenter(features, clf)\n",
    "\n",
    "# Plot the results\n",
    "fig, ax = plt.subplots(1, 2, sharex=True, sharey=True, figsize=(9, 4))\n",
    "ax[0].imshow(segmentation.mark_boundaries(img, result, mode='thick'))\n",
    "ax[0].contour(training_labels, colors='red', linewidths=1)\n",
    "ax[0].set_title('Image, mask and segmentation boundaries')\n",
    "ax[1].imshow(result)\n",
    "ax[1].set_title('Segmentation')\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(9, 4))\n",
    "l = len(clf.feature_importances_)\n",
    "feature_importance = (\n",
    "    clf.feature_importances_[: l // 3],\n",
    "    clf.feature_importances_[l // 3 : 2 * l // 3],\n",
    "    clf.feature_importances_[2 * l // 3 :],\n",
    ")\n",
    "sigmas = np.logspace(\n",
    "    np.log2(sigma_min),\n",
    "    np.log2(sigma_max),\n",
    "    num=int(np.log2(sigma_max) - np.log2(sigma_min) + 1),\n",
    "    base=2,\n",
    "    endpoint=True,\n",
    ")\n",
    "for ch, color in zip(range(3), ['r', 'g', 'b']):\n",
    "    ax[0].plot(sigmas, feature_importance[ch][::3], 'o', color=color)\n",
    "    ax[0].set_title(\"Intensity features\")\n",
    "    ax[0].set_xlabel(\"$\\\\sigma$\")\n",
    "for ch, color in zip(range(3), ['r', 'g', 'b']):\n",
    "    ax[1].plot(sigmas, feature_importance[ch][1::3], 'o', color=color)\n",
    "    ax[1].plot(sigmas, feature_importance[ch][2::3], 's', color=color)\n",
    "    ax[1].set_title(\"Texture features\")\n",
    "    ax[1].set_xlabel(\"$\\\\sigma$\")\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = \"/Users/andreas_chiocchetti/develop/Organoid_Morphology/data/OneDrive_75_12-10-2024/20240229_DH_2x_B22_H9_NTC_1_dish2_6.bmp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the CLF as a pickle file\n",
    "import pickle\n",
    "with open('clf.pkl', 'wb') as f:\n",
    "    pickle.dump(clf, f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segmentations = []\n",
    "for i in tqdm(range(len(image_files)), desc = 'Segmenting images'):\n",
    "    image = cv2.imread(os.path.join(image_path, image_files[i]))\n",
    "    # image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    img_new = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "    features_new = features_func(img_new)\n",
    "    segmentations.append(future.predict_segmenter(features_new, clf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#image = cv2.imread(os.path.join(image_path, image_files[2]))\n",
    "## image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "#image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "#img_new = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "\n",
    "for image in segmented_organoids:\n",
    "\n",
    "    img_new = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "\n",
    "    features_new = features_func(img_new)\n",
    "    result_new = future.predict_segmenter(features_new, clf)\n",
    "    fig, ax = plt.subplots(1, 2, sharex=True, sharey=True, figsize=(6, 4))\n",
    "    ax[0].imshow(segmentation.mark_boundaries(img_new, result_new, mode='thick'))\n",
    "    ax[0].set_title('Image')\n",
    "    ax[1].imshow(result_new)\n",
    "    cbar = plt.colorbar(ax[1].imshow(result_new), ax=ax[1], orientation='vertical')\n",
    "    ax[1].set_title('Segmentation')\n",
    "    fig.tight_layout()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(len(image_files)), desc = 'Plotting images'):\n",
    "    image = cv2.imread(os.path.join(image_path, image_files[i]))\n",
    "\n",
    "    fig, ax = plt.subplots(1, 2, sharex=True, sharey=True, figsize=(6, 4))\n",
    "    ax[0].imshow(segmentation.mark_boundaries(image, segmentations[i], mode='thick'))\n",
    "    ax[0].set_title('Image')\n",
    "    ax[1].imshow(segmentations[i])\n",
    "    ax[1].set_title('Segmentation')\n",
    "    fig.tight_layout()\n",
    "\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
